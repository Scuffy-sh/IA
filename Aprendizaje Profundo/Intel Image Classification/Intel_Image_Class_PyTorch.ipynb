{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsSiM1hM5Tp1"
   },
   "source": [
    "<font color=\"64D7F5\">--Comprobación de GPU y versiones--</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1756459749078,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "yn4tqecd5Wzi",
    "outputId": "4ae16152-c89d-4de0-e98c-046893982a68"
   },
   "outputs": [],
   "source": [
    "# Comprobar GPU y versiones\n",
    "import torch, platform\n",
    "print(\"PyTorch:\", torch.__version__) # Versión de PyTorch\n",
    "print(\"Python:\", platform.python_version()) # Versión de Python\n",
    "print(\"GPU disponible:\", torch.cuda.is_available()) # Disponibilidad de GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nombre de la GPU:\", torch.cuda.get_device_name(0)) # Nombre de la GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3o_V7mD3k11"
   },
   "source": [
    "<font color=\"64D7F5\">--Instalación de modulos--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4948,
     "status": "ok",
     "timestamp": 1756459754029,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "Vul1F8J93O8y",
    "outputId": "d525115d-ae01-4d8f-8231-a63880becd53"
   },
   "outputs": [],
   "source": [
    "# Instalación de Kaggle\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCmGKKip3u4m"
   },
   "source": [
    "<font color=\"64D7F5\">--Configuración del entorno de trabajo y Dataset(Kaggle)--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 19910,
     "status": "ok",
     "timestamp": 1756459773935,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "7zycLuHR3t76",
    "outputId": "069052b9-f090-46e3-bcca-e2dd360dc54d"
   },
   "outputs": [],
   "source": [
    "# Subir tu kaggle.json desde tu cuenta de Kaggle\n",
    "from google.colab import files\n",
    "files.upload() # selecciona tu kaggle.json\n",
    "\n",
    "# Crear carpeta para credenciales\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Descargar el Dataset\n",
    "!kaggle datasets download -d puneet6060/intel-image-classification -p /content/intel-image-classification\n",
    "!unzip /content/intel-image-classification/intel-image-classification.zip -d /content/intel-image-classification\n",
    "\n",
    "# Verificar estructura de directorios del Dataset\n",
    "!find /content/intel-image-classification/ -type d -maxdepth 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-vXkWTg6_wQ"
   },
   "source": [
    "<font color=\"64D7F5\">--Importar librerias necesarias--              \n",
    "--Definir PATHs--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1756459773964,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "X9aEHDxZ7Fxk"
   },
   "outputs": [],
   "source": [
    "# Importando librerias necesarias\n",
    "from pathlib import Path\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Definiendo los PATHs sobre cada parte del Dataset\n",
    "root = Path(\"/content/intel-image-classification\") # Directorio raiz\n",
    "train_dir = root / \"seg_train\"/\"seg_train\" # Directorio de entrenamiento\n",
    "test_dir = root / \"seg_test\"/\"seg_test\" # Directorio de prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2HbIIov7_oU"
   },
   "source": [
    "<font color=\"64D7F5\">--Definiendo semilla de la aleatoriedad--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756459773967,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "q33cRgID8GSQ"
   },
   "outputs": [],
   "source": [
    "# Fijar la semilla para reproducibilidad\n",
    "Seed = 12\n",
    "random.seed(Seed); np.random.seed(Seed); torch.manual_seed(Seed); torch.cuda.manual_seed_all(Seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cuwd60G8XGY"
   },
   "source": [
    "<font color=\"64D7F5\">--Conteo de imagenes por clase--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1756459774240,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "gY9aWStY8aGv"
   },
   "outputs": [],
   "source": [
    "# Definiendo función para el conteo de imagenes por clase\n",
    "def count_images_by_class(folder):\n",
    "    counts = {} # Diccionario para contar imágenes por clase\n",
    "    for cls in sorted(os.listdir(folder)): # Iterar sobre las clases\n",
    "        p = os.path.join(folder, cls) # Ruta del directorio de la clase\n",
    "        if os.path.isdir(p): # Verificar si es un directorio\n",
    "            n = sum(1 for f in os.listdir(p) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))) # Contar imágenes\n",
    "            counts[cls] = n # Almacenar conteo en el diccionario\n",
    "    total = sum(counts.values()) # Total de imágenes\n",
    "    return counts, total # Retornar conteos y total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1756459774247,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "X_bzjlZa9If-",
    "outputId": "63240d88-2714-4f03-ce40-58526762133d"
   },
   "outputs": [],
   "source": [
    "#Conteo de imagenes por sección\n",
    "train_counts, train_total = count_images_by_class(str(train_dir)) #Entrenamiento\n",
    "test_counts, test_total = count_images_by_class(str(test_dir)) #Prueba\n",
    "\n",
    "#Mostrando el resultado\n",
    "print(\"Clases (train):\", list(train_counts.keys()))\n",
    "print(\"Imágenes train por clase:\", train_counts)\n",
    "print(\"TOTAL train:\", train_total)\n",
    "print(\"TOTAL test:\", test_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1__XGwJ_8so"
   },
   "source": [
    "<font color=\"64D7F5\">--Aplicando DataAugmentation(ImageNet)--               \n",
    "<font color=\"64D7F5\">--Técnicas Clásicas--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1756459774266,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "49uPEsVSANeo",
    "outputId": "c001c50d-a0eb-468e-a43b-b01c1d4310eb"
   },
   "outputs": [],
   "source": [
    "# Definiendo las transformaciones de datos\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "\n",
    "img_size = 224 # Tamaño de las imágenes\n",
    "imagenet_mean = [0.485, 0.456, 0.406] # Media de ImageNet\n",
    "imagenet_std = [0.229, 0.224, 0.225] # Desviación estándar de ImageNet\n",
    "\n",
    "# Definiendo las transformaciones de datos para el conjunto de entrenamiento\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)), # Recorte aleatorio y redimensionado\n",
    "    transforms.RandomHorizontalFlip(), # Flip horizontal aleatorio\n",
    "    transforms.RandomVerticalFlip(p=0.1), # Flip vertical aleatorio\n",
    "    transforms.RandomRotation(15), # Rotación aleatoria\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1,0.1), scale=(0.9,1.1)), # Transformación afín aleatoria\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Variación de color\n",
    "    AutoAugment(AutoAugmentPolicy.IMAGENET), # Aumento de imagen ImageNet\n",
    "    transforms.ToTensor(), # Conversión a tensor\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std), # Normalización\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.25)) # Borrado aleatorio\n",
    "])\n",
    "\n",
    "# Definiendo las transformaciones de datos para el conjunto de evaluación\n",
    "eval_tfms = transforms.Compose([\n",
    "    transforms.Resize(int(img_size * 1.14)), # Redimensionamiento\n",
    "    transforms.CenterCrop(img_size), # Recorte central\n",
    "    transforms.ToTensor(), # Conversión a tensor\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std) # Normalización\n",
    "])\n",
    "\n",
    "# Creamos un ImageFolder \"base\" que usaremos para extraer labels de forma estratificada\n",
    "full_train_for_labels = datasets.ImageFolder(str(train_dir)) # Dataset completo para entrenamiento\n",
    "class_to_idx = full_train_for_labels.class_to_idx # Mapeo de clases a índices\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()} # Mapeo de índices a clases\n",
    "num_classes = len(class_to_idx) # Número de clases\n",
    "num_classes, class_to_idx # Número de clases y mapeo de clases a índices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtyN5TDehpHm"
   },
   "source": [
    "<font color=\"64D7F5\">--Aplicando DataAugmentation(MixUp)--               \n",
    "<font color=\"64D7F5\">--Técnicas Modernas--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1756459774363,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "jyBCQbFDh8Px"
   },
   "outputs": [],
   "source": [
    "# Función para aplicar MixUp\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha) # Parámetro de mezcla\n",
    "    batch_size = x.size()[0] # Tamaño del batch\n",
    "    index = torch.randperm(batch_size).to(x.device) # Índices aleatorios\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :] # Mezcla de imágenes\n",
    "    y_a, y_b = y, y[index] # Etiquetas originales y mezcladas\n",
    "    return mixed_x, y_a, y_b, lam # Retornamos las imágenes y etiquetas mezcladas\n",
    "\n",
    "# Función para calcular la pérdida de MixUp\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b) # Pérdida de MixUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghphL9akBtTp"
   },
   "source": [
    "<font color=\"64D7F5\">--División del Dataset de entrenamiento en entrenamiento y validación--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1756459774379,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "-c-ExOOwB4n8",
    "outputId": "e2176320-fab2-459a-f20b-059b1b108546"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "targets = [y for (_, y) in full_train_for_labels.samples] # labels alineadas con el orden interno\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=Seed) # División estratificada\n",
    "train_idx, val_idx = next(sss.split(np.zeros(len(targets)), targets)) # Índices de entrenamiento y validación\n",
    "\n",
    "# OJO: hay que usar el MISMO orden de archivos para los dos datasets (transform distintos)\n",
    "full_train_with_aug = datasets.ImageFolder(str(train_dir), transform=train_tfms) # Dataset completo con aumentos\n",
    "full_train_eval = datasets.ImageFolder(str(train_dir), transform=eval_tfms) # Dataset completo para evaluación\n",
    "\n",
    "# Creamos los subsets para entrenamiento y validación\n",
    "train_ds = Subset(full_train_with_aug, train_idx) # Subconjunto de entrenamiento\n",
    "val_ds = Subset(full_train_eval, val_idx) # Subconjunto de validación\n",
    "\n",
    "# Creamos el subset para el conjunto de prueba\n",
    "test_ds = datasets.ImageFolder(str(test_dir), transform=eval_tfms)\n",
    "\n",
    "# Mostramos el resultado\n",
    "print(\"Train:\", len(train_ds), \"Val:\", len(val_ds), \"Test:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvWg-tYmC3hH"
   },
   "source": [
    "<font color=\"64D7F5\">--DataLoaders (batching, workers, pin_memory)--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756459774410,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "nqUh4z1sC5Ma",
    "outputId": "af20e379-4d26-4be9-c2d3-13f22d278c04"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64 # Tamaño del batch\n",
    "num_workers = 2 # Número de trabajadores(en Colab suele ir bien 2)\n",
    "pin_memory = torch.cuda.is_available() # Pin memory para acelerar la transferencia de datos\n",
    "\n",
    "# Creamos los DataLoaders para el conjunto de entrenamiento\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "# Creamos el DataLoader para el conjunto de validación\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "# Creamos el DataLoader para el conjunto de prueba\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "# Mostramos el resultado\n",
    "print(\"Batches - Lotes:\\n\")\n",
    "print(\"Train:\", len(train_loader), \"Val:\", len(val_loader), \"Test:\", len(test_loader))\n",
    "print(\"Classes:\", idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6iOla1a4YrY6"
   },
   "source": [
    "<font color=\"64D7F5\">--Vista rápida de un batch (sanity check)--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "executionInfo": {
     "elapsed": 3082,
     "status": "ok",
     "timestamp": 1756459777484,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "5N3BlkGiYub3",
    "outputId": "9a4ac101-a410-4885-f6ac-cd03b40a9ef3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "# Visualizamos algunas imágenes del conjunto de entrenamiento\n",
    "plt.figure(figsize=(10, 10)) # Tamaño de la figura\n",
    "\n",
    "imgs, labels = next(iter(train_loader)) # Obtenemos un batch de imágenes y etiquetas\n",
    "grid = torchvision.utils.make_grid(imgs[:32], nrow=8, padding=2) # Creamos una cuadrícula de imágenes\n",
    "\n",
    "# Des-normalizamos para visualizar\n",
    "npimg = grid.numpy() # Convertimos a numpy\n",
    "mean = np.array(imagenet_mean)[:, None, None] # Creamos un array de media\n",
    "std = np.array(imagenet_std)[:, None, None] # Creamos un array de desviación estándar\n",
    "npimg = (std * npimg) + mean # Des-normalizamos\n",
    "npimg = np.clip(npimg, 0, 1) # Clampeamos a [0, 1]\n",
    "\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0))) # Mostramos la imagen\n",
    "plt.axis(\"off\") # Ocultamos los ejes\n",
    "print(\"Etiquetas:\", [idx_to_class[int(l)] for l in labels[:32]]) # Mostramos las etiquetas\n",
    "plt.show() # Mostramos la figura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz8UoaOvcGEg"
   },
   "source": [
    "<font color=\"64D7F5\">--Definición de los modelos SimpleCNN, ResNet18 y EfficientNet-B0--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756459777488,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "niCxJM52cJPO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "# Construimos una CNN simple\n",
    "def build_simpleCNN(num_classes):\n",
    "    class SimpleCNN(nn.Module): # Definimos la arquitectura de la red\n",
    "        def __init__(self, num_classes): # Inicializamos la red\n",
    "            super(SimpleCNN, self).__init__() # Llamamos al constructor de la clase base\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1) # Capa convolucional 1\n",
    "            self.bn1 = nn.BatchNorm2d(32) # Capa de normalización 1\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # Capa convolucional 2\n",
    "            self.bn2 = nn.BatchNorm2d(64) # Capa de normalización 2\n",
    "            self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # Capa convolucional 3\n",
    "            self.bn3 = nn.BatchNorm2d(128) # Capa de normalización 3\n",
    "            self.pool = nn.MaxPool2d(2, 2) # Capa de max pooling\n",
    "            self.fc1 = nn.Linear(128 * (img_size//8) * (img_size//8), 256) # Capa totalmente conectada 1\n",
    "            self.fc2 = nn.Linear(256, num_classes) # Capa totalmente conectada 2\n",
    "            self.dropout = nn.Dropout(0.5) # Capa de dropout\n",
    "\n",
    "        # Propagación hacia adelante\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.bn1(self.conv1(x)))) # 224 -> 112\n",
    "            x = self.pool(F.relu(self.bn2(self.conv2(x)))) # 112 -> 56\n",
    "            x = self.pool(F.relu(self.bn3(self.conv3(x)))) # 56 -> 28\n",
    "            x = x.view(x.size(0), -1) # aplanar\n",
    "            x = F.relu(self.fc1(x)) # capa totalmente conectada 1\n",
    "            x = self.dropout(x) # capa de dropout\n",
    "            x = self.fc2(x) # capa totalmente conectada 2\n",
    "            return x # capa de salida\n",
    "    # Fin de la clase\n",
    "    return SimpleCNN(num_classes)\n",
    "\n",
    "\n",
    "# ResNet18 preentrenado\n",
    "def build_ResNet18(num_classes, fine_tune=False): # Construcción de la arquitectura ResNet18\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1) # Cargar modelo preentrenado\n",
    "    if not fine_tune: # Congelar capas\n",
    "        for param in model.parameters(): # Congelar todos los parámetros\n",
    "            param.requires_grad = False # Congelar parámetros\n",
    "    else: # Descongelar capas específicas\n",
    "        for name, param in model.named_parameters(): # Iterar sobre los parámetros nombrados\n",
    "            if \"layer4\" in name or \"fc\" in name: # Descongelar capas específicas\n",
    "                param.requires_grad = True # Descongelar parámetros\n",
    "            else:\n",
    "                param.requires_grad = False # Congelar parámetros\n",
    "\n",
    "    # Ajustar la capa final para el número de clases\n",
    "    in_features = model.fc.in_features # Obtener el número de características de entrada\n",
    "    # Reemplazar la capa totalmente conectada\n",
    "    model.fc = nn.Sequential( # Nueva capa totalmente conectada\n",
    "        nn.Linear(in_features, 256), # Capa totalmente conectada 1\n",
    "        nn.ReLU(), # Capa de activación 1\n",
    "        nn.Dropout(0.5), # Capa de dropout\n",
    "        nn.Linear(256, num_classes) # Capa totalmente conectada 2\n",
    "    )\n",
    "    return model # Modelo ajustado\n",
    "\n",
    "# EfficientNet-B0 preentrenado\n",
    "def build_EfficientNetB0(num_classes, fine_tune=False):\n",
    "    from torchvision import models\n",
    "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1) # Cargar modelo preentrenado\n",
    "\n",
    "    if not fine_tune: # Congelar capas\n",
    "        for param in model.parameters(): # Congelar todos los parámetros\n",
    "            param.requires_grad = False # Congelar parámetros\n",
    "    else: # Solo fine-tune en las últimas capas\n",
    "        for name, param in model.named_parameters(): # Iterar sobre los parámetros nombrados\n",
    "            if \"features.6\" in name or \"features.7\" in name or \"classifier\" in name: # Descongelar capas específicas\n",
    "                param.requires_grad = True # Descongelar parámetros\n",
    "            else:\n",
    "                param.requires_grad = False # Congelar parámetros\n",
    "\n",
    "    # Ajustar la capa final para el número de clases\n",
    "    in_features = model.classifier[1].in_features # Obtener el número de características de entrada\n",
    "    # Reemplazar la capa totalmente conectada\n",
    "    model.classifier = nn.Sequential( # Nueva capa totalmente conectada\n",
    "        nn.Linear(in_features, 256), # Capa totalmente conectada\n",
    "        nn.ReLU(), # Capa de activación\n",
    "        nn.Dropout(p=0.4), # Capa de dropout\n",
    "        nn.Linear(256, num_classes) # Capa totalmente conectada\n",
    "    )\n",
    "    return model # Modelo ajustado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTygLI3IdpdK"
   },
   "source": [
    "<font color=\"64D7F5\">--Loop de entrenamiento y validación--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756459777491,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "uwOSVYUOdrqw"
   },
   "outputs": [],
   "source": [
    "# Definiendo una función para el entrenamiento de una época\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, use_mixup=True):\n",
    "    model.train() # Establecer el modelo en modo de entrenamiento\n",
    "    running_loss, correct, total = 0.0, 0, 0 # Inicializar métricas\n",
    "\n",
    "    for imgs, labels in loader: # Iterar sobre el DataLoader\n",
    "        imgs, labels = imgs.to(device), labels.to(device) # Mover imágenes y etiquetas al dispositivo\n",
    "        optimizer.zero_grad() # Limpiar gradientes\n",
    "\n",
    "        if use_mixup: # Aplicar MixUp\n",
    "            imgs, targets_a, targets_b, lam = mixup_data(imgs, labels) # Aplicar MixUp\n",
    "            outputs = model(imgs) # Propagación hacia adelante\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam) # Calcular la pérdida de MixUp\n",
    "            _, preds = outputs.max(1) # Obtener las predicciones\n",
    "            correct += (lam * preds.eq(targets_a).sum().item() + (1 - lam) * preds.eq(targets_b).sum().item()) # Acumular aciertos\n",
    "\n",
    "        else: # No aplicar MixUp\n",
    "            outputs = model(imgs) # Propagación hacia adelante\n",
    "            loss = criterion(outputs, labels) # Calcular pérdida\n",
    "            _, preds = outputs.max(1) # Obtener las predicciones\n",
    "            correct += preds.eq(labels).sum().item() # Acumular aciertos\n",
    "\n",
    "        loss.backward() # Retropropagación\n",
    "        optimizer.step() # Actualizar pesos\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0) # Acumular pérdida\n",
    "        total += labels.size(0) # Acumular total\n",
    "\n",
    "    # Retornar métricas\n",
    "    return running_loss/total, correct/total\n",
    "\n",
    "# Definir la función de evaluación\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval() # Establecer el modelo en modo de evaluación\n",
    "    running_loss, correct, total = 0.0, 0, 0 # Inicializar métricas\n",
    "    with torch.no_grad(): # Desactivar el cálculo de gradientes\n",
    "        for imgs, labels in loader: # Iterar sobre el DataLoader\n",
    "            imgs, labels = imgs.to(device), labels.to(device) # Mover imágenes y etiquetas al dispositivo\n",
    "            outputs = model(imgs) # Propagación hacia adelante\n",
    "            loss = criterion(outputs, labels) # Calcular la pérdida\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0) # Acumular pérdida\n",
    "            _, preds = outputs.max(1) # Obtener las predicciones\n",
    "            correct += preds.eq(labels).sum().item() # Acumular aciertos\n",
    "            total += labels.size(0) # Acumular total\n",
    "\n",
    "    # Retornar métricas\n",
    "    return running_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGYF2XYv-fiR"
   },
   "source": [
    "<font color=\"64D7F5\">--Seleccionar modelo a entrenar--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756459777496,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "EC0vTsar-hzV"
   },
   "outputs": [],
   "source": [
    "# Definir el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Definir el tipo de modelo\n",
    "type_model = \"EfficientNetB0\" # \"SimpleCNN\", \"ResNet18\" o \"EfficientNetB0\"\n",
    "\n",
    "# Construir el modelo de acuerdo al tipo seleccionado\n",
    "if type_model == \"SimpleCNN\":\n",
    "  model = build_simpleCNN(num_classes).to(device)\n",
    "elif type_model == \"ResNet18\":\n",
    "  model = build_ResNet18(num_classes).to(device)\n",
    "elif type_model == \"EfficientNetB0\":\n",
    "  model = build_EfficientNetB0(num_classes, fine_tune=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pr870Hfrdg7I"
   },
   "source": [
    "<font color=\"64D7F5\">--Definir pérdida y optimizador--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756459777500,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "ScmnqL_xdjHj"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Definir el optimizador de acuerdo al tipo de modelo\n",
    "if type_model == \"SimpleCNN\":\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4) # Optimizador para SimpleCNN\n",
    "else: #ResNet18 / EfficientNetB0\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4) # Optimizador para ResNet18 y EfficientNetB0\n",
    "\n",
    "# Definir la función de pérdida y el programador de tasa de aprendizaje\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMBaIUzFfQSO"
   },
   "source": [
    "<font color=\"64D7F5\">--Entrenamiento del modelo (varias épocas)--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1835387,
     "status": "ok",
     "timestamp": 1756461612889,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "ayd8lpntfRm0",
    "outputId": "ddd17c0a-a26e-44e5-ad83-e2d3ebc16ce3"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "epochs = 30 # Número de épocas\n",
    "best_acc = 0.0 # Mejor precisión\n",
    "best_model_wts = copy.deepcopy(model.state_dict()) # Mejor pesos del modelo\n",
    "\n",
    "patience = 3 # Paciencia para early stopping\n",
    "counter = 0 # Contador para early stopping\n",
    "\n",
    "# Historial de métricas\n",
    "history = {\n",
    "      'train_loss': [], # Pérdida de entrenamiento\n",
    "      'train_acc': [], # Precisión de entrenamiento\n",
    "      'val_loss': [], # Pérdida de validación\n",
    "      'val_acc': [] # Precisión de validación\n",
    "}\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs, best_acc, history):\n",
    "  # Entrenamiento\n",
    "  for epoch in range(epochs): # Iterar sobre las épocas\n",
    "      train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device) # Entrenamiento de una época\n",
    "      val_loss, val_acc = evaluate(model, val_loader, criterion, device) # Evaluación del modelo\n",
    "\n",
    "      history['train_loss'].append(train_loss) # Pérdida de entrenamiento\n",
    "      history['train_acc'].append(train_acc) # Precisión de entrenamiento\n",
    "      history['val_loss'].append(val_loss) # Pérdida de validación\n",
    "      history['val_acc'].append(val_acc) # Precisión de validación\n",
    "      # Imprimir métricas\n",
    "      print(\"---------------------------------------\")\n",
    "      print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "      print(f\"Train Loss: {train_loss:.4f}, Train Acc: {100 * train_acc:.2f}%\")\n",
    "      print(f\"Val Loss: {val_loss:.4f}, Val Acc: {100 * val_acc:.2f}%\")\n",
    "\n",
    "      # Ajustar el LR según val_loss\n",
    "      old_lr = optimizer.param_groups[0]['lr'] # Guardar el LR antiguo\n",
    "      scheduler.step(val_loss) # Ajustar el LR\n",
    "      new_lr = optimizer.param_groups[0]['lr'] # Guardar el nuevo LR\n",
    "      if new_lr != old_lr: # Si el LR ha cambiado\n",
    "          print(f\"Reduciendo el LR: {old_lr} -> {new_lr}\") # Imprimir el cambio de LR\n",
    "\n",
    "      # Guardar el mejor modelo\n",
    "      if val_acc > best_acc: # Si la precisión de validación es mejor que la mejor precisión\n",
    "          best_acc = val_acc # Actualizar la mejor precisión\n",
    "          best_model_wts = copy.deepcopy(model.state_dict()) # Guardar los mejores pesos del modelo\n",
    "          counter = 0 # Reiniciar el contador\n",
    "          # Imprimir mensaje de éxito\n",
    "          print(\"Mejor modelo entrenado y guardado\")\n",
    "      else: # Si no hay mejora\n",
    "          counter += 1 # Incrementar el contador\n",
    "          # Imprimir mensaje de falta de mejora\n",
    "          print(f\"Sin mejora ({counter}/{patience})\")\n",
    "\n",
    "\n",
    "      if counter >= patience: # Si el contador alcanza la paciencia(3)\n",
    "          # Imprimir mensaje de early stopping\n",
    "          print(\"Early stopping activado\")\n",
    "          break # Detener el entrenamiento\n",
    "\n",
    "  # Devuelve el historial, los mejores pesos del modelo y la mejor precisión\n",
    "  return history, best_model_wts, best_acc\n",
    "\n",
    "# Llamando a la función de entrenamiento --> Fase de entrenamiento 1\n",
    "training_phase1, best_model_wts, best_acc = train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs, best_acc, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWAEicfyVu1s"
   },
   "source": [
    "<font color=\"64D7F5\">--Guardar modelos entrenados en un directorio del Drive--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1583,
     "status": "ok",
     "timestamp": 1756461614467,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "8lQdqe13V28o",
    "outputId": "5bb575ed-1fe5-4776-b16f-265c7621e954"
   },
   "outputs": [],
   "source": [
    "#Montar el directorio del Google Drive en Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1756461614513,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "SYUUIrz-V6qu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Crear el directorio para guardar los modelos entrenados\n",
    "save_dir = \"/content/drive/MyDrive/Modelos_entrenados_ML_DL/Intel_Image_Class_PyTorch_CNN\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1756465062309,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "lrhlqXQaV_LD",
    "outputId": "bf5637bd-4cb7-4862-e42d-9a3ce7960f28"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def save_model(model, type_model, num_classes, save_dir, phase_name=\"phase\", best_acc=best_acc):\n",
    "  \"\"\"\n",
    "    Guarda un modelo entrenado en formato checkpoint de PyTorch.\n",
    "\n",
    "    Args:\n",
    "        model: Modelo entrenado (nn.Module).\n",
    "        type_model: Tipo de modelo (str), ej. \"SimpleCNN\", \"ResNet18\", \"EfficientNetB0\".\n",
    "        num_classes: Número de clases del dataset.\n",
    "        save_dir: Directorio donde guardar el checkpoint.\n",
    "        phase_name: Nombre de la fase de entrenamiento (ej. \"phase1\", \"phase2\").\n",
    "    \"\"\"\n",
    "\n",
    "  # Aplicar los mejores pesos antes de guardar\n",
    "  model.load_state_dict(best_model_wts)\n",
    "\n",
    "  # Guardar en checkpoint: tipo de modelo, clases y pesos\n",
    "  checkpoint = {\n",
    "      \"type_model\": type_model, # Tipo de modelo\n",
    "      \"num_classes\": num_classes, # Número de clases\n",
    "      \"state_dict\": model.state_dict(), # Pesos del modelo\n",
    "      \"best_acc\": best_acc # Mejor precisión\n",
    "  }\n",
    "\n",
    "  # Guardar el modelo (mejor modelo)\n",
    "  model_path = os.path.join(save_dir, f\"{type_model}_{phase_name}.pth\") # Ruta del modelo\n",
    "  torch.save(checkpoint, model_path) # Guardar el modelo\n",
    "  # Imprimir la mejor precisión y la ruta del modelo guardado\n",
    "  print(f\"Entrenamiento terminado. Mejor val_acc: {100 * best_acc:.2f}%\")\n",
    "  print(f\"Modelo guardado en: {model_path}\")\n",
    "\n",
    "  return model_path\n",
    "\n",
    "# Guardar el modelo de la fase 1\n",
    "save_model(model, type_model, num_classes, save_dir, phase_name=\"phase1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oev5SeznWGkJ"
   },
   "source": [
    "<font color=\"64D7F5\">--Cargar los modelos entrenados y el historial--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1756461614897,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "9Vzy9zAOWL63",
    "outputId": "c24ae521-22bb-4411-b808-fbdd2df33d8e"
   },
   "outputs": [],
   "source": [
    "# Cargar checkpoint\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Reconstruir el modelo según el modelo guardado\n",
    "if checkpoint[\"type_model\"] == \"ResNet18\":\n",
    "  model_loaded = build_ResNet18(checkpoint[\"num_classes\"]).to(device) # Reconstruir modelo ResNet18\n",
    "elif checkpoint[\"type_model\"] == \"SimpleCNN\":\n",
    "  model_loaded = build_SimpleCNN(checkpoint[\"num_classes\"]).to(device) # Reconstruir modelo SimpleCNN\n",
    "elif checkpoint[\"type_model\"] == \"EfficientNetB0\":\n",
    "  model_loaded = build_EfficientNetB0(checkpoint[\"num_classes\"]).to(device) # Reconstruir modelo EfficientNetB0\n",
    "\n",
    "# Cargar los pesos del modelo\n",
    "model_loaded.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model_loaded.eval() # Establecer el modelo en modo de evaluación\n",
    "\n",
    "# Imprimir mensaje de éxito\n",
    "print(f\"Modelo {checkpoint['type_model']} cargado correctamente en el dispositivo {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsJaLrFj01PX"
   },
   "source": [
    "<font color=\"64D7F5\">--Evaluación en test--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7773,
     "status": "ok",
     "timestamp": 1756461622668,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "FjgqLnLo06aa",
    "outputId": "c4266dac-72f5-43c1-c0d6-f3ae9e26ad1e"
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = evaluate(model_loaded, test_loader, criterion, device)\n",
    "# Imprimir métricas\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {100 * test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc3EA0IZAL_f"
   },
   "source": [
    "<font color=\"64D7F5\">--Curvas de entrenamiento--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1756461622898,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "OA0XNDo4AK4I",
    "outputId": "e32399b5-cb0a-412e-a2f4-ab0694824f70"
   },
   "outputs": [],
   "source": [
    "# Obtener el número de épocas entrenadas\n",
    "epochs_ran = len(history['train_loss'])\n",
    "\n",
    "# Graficar las métricas de entrenamiento(Pérdida)\n",
    "plt.figure(figsize=(12, 5)) # Tamaño de la figura\n",
    "plt.subplot(1, 2, 1) # Gráfica de Pérdida\n",
    "plt.plot(range(1, epochs_ran + 1), history['train_loss'], label='Train Loss') # Pérdida de entrenamiento\n",
    "plt.plot(range(1, epochs_ran + 1), history['val_loss'], label='Val Loss') # Pérdida de validación\n",
    "plt.xlabel('Epochs') # Épocas\n",
    "plt.ylabel('Loss') # Pérdida\n",
    "plt.legend() # Leyenda\n",
    "plt.title('Curva de Pérdida') # Título de la gráfica\n",
    "\n",
    "# Graficar las métricas de entrenamiento(Precisión)\n",
    "plt.subplot(1, 2, 2) # Gráfica de Precisión\n",
    "plt.plot(range(1, epochs_ran + 1), [a*100 for a in history['train_acc']], label='Train Acc') # Precisión de entrenamiento\n",
    "plt.plot(range(1, epochs_ran + 1), [a*100 for a in history['val_acc']], label='Val Acc') # Precisión de validación\n",
    "plt.xlabel('Epochs') # Épocas\n",
    "plt.ylabel('Accuracy (%)') # Precisión\n",
    "plt.legend() # Leyenda\n",
    "plt.title('Curva de Precisión') # Título de la gráfica\n",
    "\n",
    "plt.show() # Mostrar las gráficas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMJCv4uFA19G"
   },
   "source": [
    "<font color=\"64D7F5\">--Matriz de confusión y reporte--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 842
    },
    "executionInfo": {
     "elapsed": 9207,
     "status": "ok",
     "timestamp": 1756461632103,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "jH7cO2XtA5vU",
    "outputId": "abf9c00f-2184-4810-fc45-a3e0bbf56891"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, balanced_accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "y_true, y_pred = [], [] # Listas para almacenar las etiquetas verdaderas y las predicciones\n",
    "model.eval() # Establecer el modelo en modo de evaluación\n",
    "with torch.no_grad(): # Desactivar el cálculo de gradientes\n",
    "    for imgs, labels in test_loader: # Iterar sobre el conjunto de prueba\n",
    "        imgs, labels = imgs.to(device), labels.to(device) # Mover imágenes y etiquetas al dispositivo\n",
    "        outputs = model(imgs) # Obtener las salidas del modelo\n",
    "        _, preds = outputs.max(1) # Obtener las predicciones\n",
    "        y_true.extend(labels.cpu().numpy()) # Almacenar las etiquetas verdaderas\n",
    "        y_pred.extend(preds.cpu().numpy()) # Almacenar las predicciones\n",
    "\n",
    "# Imprimir un resumen de las métricas\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, target_names=idx_to_class.values()))\n",
    "\n",
    "# Imprimir el F1 Score y la Balanced Accuracy\n",
    "print(f\"F1 Score: {f1_score(y_true, y_pred, average='macro'):.2f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_true, y_pred):.2f}\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred) # Calcular la matriz de confusión\n",
    "\n",
    "# Graficar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6)) # Tamaño de la figura\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=idx_to_class.values(), yticklabels=idx_to_class.values()) # Mapa de calor\n",
    "plt.xlabel('Predicción') # Etiqueta del eje x\n",
    "plt.ylabel('Real') # Etiqueta del eje y\n",
    "plt.title('Matriz de Confusión') # Título de la gráfica\n",
    "plt.show() # Mostrar la gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwhPoLVmBcRl"
   },
   "source": [
    "<font color=\"64D7F5\">--Visualización de predicciones--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1756461779008,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "4qh7Z1K8BfqD",
    "outputId": "f28c4272-09d1-4367-d8aa-52c88ff2bbd4"
   },
   "outputs": [],
   "source": [
    "mean = np.array(imagenet_mean)[:, None, None] # Media de ImageNet\n",
    "std = np.array(imagenet_std)[:, None, None] # Desviación estándar de ImageNet\n",
    "\n",
    "# Función para mostrar predicciones aleatorias\n",
    "# n es el número de imágenes a mostrar\n",
    "def show_random_predictions(model, loader, n=8):\n",
    "    model.eval() # Establecer el modelo en modo de evaluación\n",
    "    idxs = random.sample(range(len(loader.dataset)), n) # Seleccionar índices aleatorios\n",
    "    imgs, labels = [], [] # Listas para almacenar imágenes y etiquetas\n",
    "    for i in idxs: # Iterar sobre los índices seleccionados\n",
    "        img, label = loader.dataset[i] # Obtener la imagen y la etiqueta\n",
    "        imgs.append(img.unsqueeze(0)) # Añadir la imagen a la lista\n",
    "        labels.append(label) # Añadir la etiqueta a la lista\n",
    "    imgs = torch.cat(imgs).to(device) # Concatenar las imágenes y mover al dispositivo\n",
    "    labels = torch.tensor(labels).to(device) # Mover las etiquetas al dispositivo\n",
    "\n",
    "    outputs = model(imgs) # Obtener las salidas del modelo\n",
    "    _, preds = outputs.max(1) # Obtener las predicciones\n",
    "\n",
    "    # Graficar las predicciones\n",
    "    plt.figure(figsize=(15, 6)) # Tamaño de la figura\n",
    "    for i in range(n): # Iterar sobre las imágenes\n",
    "        img = imgs[i].cpu().numpy() # Convertir la imagen a un array de NumPy\n",
    "        img = np.transpose(img, (1, 2, 0)) # Transponer las dimensiones de la imagen\n",
    "        img = img * std.transpose(1, 2, 0) + mean.transpose(1, 2, 0) # Desnormalizar la imagen\n",
    "        img = np.clip(img, 0, 1) # Asegurarse de que los valores estén en el rango [0, 1]\n",
    "\n",
    "        # Determinar el color del título según la predicción\n",
    "        color = \"green\" if preds[i].item() == labels[i].item() else \"red\" # green=correcto, red=incorrecto\n",
    "        plt.subplot(2, n//2, i+1) # Crear un subplot para cada imagen\n",
    "        plt.imshow(img) # Mostrar la imagen\n",
    "        plt.axis(\"off\") # Ocultar los ejes\n",
    "        # Mostrar la etiqueta real y la predicción dependiendo del color\n",
    "        plt.title(f\"Pred: {idx_to_class[preds[i].item()]}\\nReal: {idx_to_class[labels[i].item()]}\", color=color)\n",
    "    plt.show() # Mostrar la figura\n",
    "\n",
    "# Mostrar predicciones aleatorias\n",
    "show_random_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBHuequOmji2"
   },
   "source": [
    "<font color=\"64D7F5\">--Visualización de errores más comunes(por clases)--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "executionInfo": {
     "elapsed": 11634,
     "status": "ok",
     "timestamp": 1756461811510,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "cPwW83Yfmsuv",
    "outputId": "304b7082-bd39-4967-f78c-ecc16ef31d10"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, balanced_accuracy_score\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "def show_misclassified_images(model, loader, n=12):\n",
    "    model.eval() # Establecer el modelo en modo de evaluación\n",
    "    misclassified = [] # Lista para almacenar las imágenes clasificadas incorrectamente\n",
    "\n",
    "    with torch.no_grad(): # Desactivar el cálculo de gradientes\n",
    "        for imgs, labels in loader: # Iterar sobre el DataLoader\n",
    "            imgs, labels = imgs.to(device), labels.to(device) # Mover imágenes y etiquetas al dispositivo\n",
    "            outputs = model(imgs) # Obtener las salidas del modelo\n",
    "            _, preds = outputs.max(1) # Obtener las predicciones\n",
    "\n",
    "            # Guardar índices de errores\n",
    "            for i in range(len(labels)):\n",
    "                if preds[i] != labels[i]:\n",
    "                    misclassified.append((imgs[i].cpu(), preds[i].item(), labels[i].item()))\n",
    "\n",
    "        # Imprimir el número de errors\n",
    "        print(f\"Total de errores: {len(misclassified)}\")\n",
    "\n",
    "        if len(misclassified) == 0: # Si no hay errores\n",
    "            print(\"No hay errores en este conjunto.\")\n",
    "            return\n",
    "\n",
    "        # Seleccionar aleatoriamente n errores\n",
    "        sample_errors = random.sample(misclassified, min(n, len(misclassified)))\n",
    "\n",
    "        # Graficar los errores más comunes\n",
    "        plt.figure(figsize=(15, 8)) # Tamaño de la figura\n",
    "        for i, (img_tensor, pred, label) in enumerate(sample_errors):\n",
    "            img = img_tensor.numpy().transpose(1, 2, 0) # Transponer las dimensiones de la imagen\n",
    "            img = img * std.transpose(1, 2, 0) + mean.transpose(1, 2, 0) # Desnormalizar la imagen\n",
    "            img = np.clip(img, 0, 1) # Asegurarse de que los valores estén en el rango [0, 1]\n",
    "\n",
    "            plt.subplot(3, n//3, i+1) # Crear un subplot para cada imagen\n",
    "            plt.imshow(img) # Mostrar la imagen\n",
    "            plt.axis(\"off\") # Ocultar los ejes\n",
    "            plt.title(f\"Pred: {idx_to_class[pred]}\\nReal: {idx_to_class[label]}\", color=\"red\") # Mostrar la etiqueta predecida y la real\n",
    "\n",
    "        plt.suptitle(\"Errores más comunes por clase\", fontsize=14) # Título de la gráfica\n",
    "        plt.show() # Mostrar la figura\n",
    "\n",
    "# Usando la función creada\n",
    "show_misclassified_images(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a4vYxVZoisJ"
   },
   "source": [
    "<font color=\"64D7F5\">--Encontrar las confusiones más freqüentes--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756461824823,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "I_c5pQ3soqLQ",
    "outputId": "6364eaf0-0513-47ca-c957-525da6a041d5"
   },
   "outputs": [],
   "source": [
    "def top_confusions(y_true, y_pred, idx_to_class, top_k=5):\n",
    "  cm = confusion_matrix(y_true, y_pred) # Calcular la matriz de confusión\n",
    "  confusions = [] # Lista para almacenar las confusiones\n",
    "\n",
    "  for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "      if i != j and cm[i][j] > 0: # ignoramos los aciertos (diagonal)\n",
    "        confusions.append((cm[i][j], idx_to_class[i], idx_to_class[j]))\n",
    "\n",
    "  confusions.sort(reverse=True, key=lambda x: x[0]) # Ordenar por frecuencia\n",
    "  print(f\"Top {top_k} confusiones más frecuentes:\")\n",
    "  for n, (count, real, pred) in enumerate(confusions[:top_k], 1):\n",
    "    print(f\"{n}. Real: {real} --> Pred: {pred} ({count} veces)\")\n",
    "\n",
    "  return confusions[:top_k] # Retornar las confusiones más frecuentes\n",
    "\n",
    "# Usando la función creada\n",
    "freq_confusions = top_confusions(y_true, y_pred, idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz1tJ-KNqVOO"
   },
   "source": [
    "<font color=\"64D7F5\">--Mejora en el DataAugmentation dependiendo el tipo de confusión--\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<font color=\"64D7F5\">**Mountain ↔ Glacier:** Se confunden porque ambas tienen texturas parecidas (blanco, rocas, nieve).\n",
    "\n",
    "<font color=\"64D7F5\">➜ Augmentations con color jitter (brillo/contraste) ayudan a que el modelo aprenda a diferenciar “montaña con nieve” de “glaciar puro”. Rotaciones también, porque ángulos diferentes no deberían confundir.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<font color=\"64D7F5\">**Buildings ↔ Street:**\n",
    "<font color=\"64D7F5\">Se confunden porque las calles suelen tener edificios.\n",
    "\n",
    "<font color=\"64D7F5\">➜ Distorsiones de perspectiva y rotaciones pequeñas ayudan a que el modelo aprenda que un edificio no siempre implica “street”.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<font color=\"64D7F5\">**Glacier ↔ Sea:**\n",
    "<font color=\"64D7F5\">Se confunden porque ambos pueden ser azulados y con reflejos.\n",
    "\n",
    "<font color=\"64D7F5\">➜ Augmentations con saturación y brillo ayudan a que el modelo aprenda a distinguir “azul sólido de agua” de “azul con hielo”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756461827229,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "lg0HtGXSqfoR",
    "outputId": "487ddb63-797c-4e76-e861-94d04c0558e6"
   },
   "outputs": [],
   "source": [
    "# Funcion que ugiere técnicas de data augmentation según las confusiones más comunes.\n",
    "# confusions = lista [(count, real_class, pred_class), ...]\n",
    "def suggest_augmentations(top_confusions):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    suggestions = {} # Diccionario para almacenar sugerencias\n",
    "\n",
    "    # Iterar sobre las confusiones más comunes\n",
    "    for _, real, pred in top_confusions:\n",
    "      if (real, pred) in [('mountain','glacier'), ('glacier','mountain')]:\n",
    "        # Sugerencias para montañas y glaciares\n",
    "        suggestions[real] = [\n",
    "          \"RandomResizedCrop\", \"RandomRotation(15°)\", \"ColorJitter(brightness/contrast)\",\n",
    "                \"RandomHorizontalFlip\", \"RandomVerticalFlip\", \"Zoom/Scale variations\"\n",
    "            ]\n",
    "      elif (real, pred) in [('buildings','street'), ('street','buildings')]:\n",
    "          # Sugerencias para edificios y calles\n",
    "          suggestions[real] = [\n",
    "              \"RandomRotation(10°)\", \"RandomPerspective\", \"ColorJitter\", \"RandomHorizontalFlip\"\n",
    "            ]\n",
    "      elif (real, pred) in [('glacier','sea'), ('sea','glacier')]:\n",
    "          # Sugerencias para glaciares y mares\n",
    "          suggestions[real] = [\n",
    "              \"ColorJitter(saturation/brightness)\", \"RandomRotation(10°)\", \"RandomResizedCrop\"\n",
    "            ]\n",
    "      else:\n",
    "            # Sugerencias para clases sin confusión frecuente\n",
    "            suggestions[real] = [\n",
    "              \"RandomResizedCrop\", \"RandomHorizontalFlip\", \"ColorJitter\"\n",
    "            ]\n",
    "\n",
    "    print(\"Sugerencias de Data Augmentation según las confusiones más comunes:\")\n",
    "    # Imprimir las sugerencias\n",
    "    for cls, aug in suggestions.items():\n",
    "        print(f\"- {cls.capitalize()}: {', '.join(aug)}\")\n",
    "\n",
    "    # Devolver las sugerencias\n",
    "    return suggestions\n",
    "\n",
    "# Obtener las sugerencias de data augmentation\n",
    "suggested_augmentations = suggest_augmentations(freq_confusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLqQPFjRzAU2"
   },
   "source": [
    "<font color=\"64D7F5\">--Aplicando el Data Augmentando según las confusiones obtenidas--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1756461848131,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "JFGvz-lmzN3X"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_classwise_transforms(top_confusions, input_size=224):\n",
    "    \"\"\"\n",
    "    Crea un diccionario con transforms.Compose por clase\n",
    "    basado en las confusiones más frecuentes.\n",
    "\n",
    "    Args:\n",
    "        top_confusions: lista de tuplas (count, real_class, pred_class)\n",
    "        input_size: tamaño final al que se redimensionarán las imágenes\n",
    "    \"\"\"\n",
    "    class_transforms = {}\n",
    "\n",
    "    for _, real, pred in top_confusions:\n",
    "        if (real, pred) in [('mountain','glacier'), ('glacier','mountain')]:\n",
    "            # Augmentations específicas para montañas y glaciares\n",
    "            aug = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(input_size, scale=(0.85, 1.0)), # Recorte aleatorio\n",
    "                transforms.RandomRotation(15), # Rotación aleatoria\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2), # Variación de color\n",
    "                transforms.RandomHorizontalFlip(p=0.5), # Flip horizontal\n",
    "                transforms.ToTensor(), # Convertir a tensor\n",
    "                transforms.Normalize(imagenet_mean, imagenet_std) # Normalización\n",
    "            ])\n",
    "            # Asignar las transformaciones a la clase correspondiente\n",
    "            class_transforms[real] = aug\n",
    "\n",
    "        elif (real, pred) in [('buildings','street'), ('street','buildings')]:\n",
    "            # Augmentations específicas para edificios y calles\n",
    "            aug = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(input_size, scale=(0.9, 1.0)), # Recorte aleatorio\n",
    "                transforms.RandomRotation(10), # Rotación aleatoria\n",
    "                transforms.RandomPerspective(distortion_scale=0.2, p=0.5), # Perspectiva aleatoria\n",
    "                transforms.RandomHorizontalFlip(p=0.5), # Flip horizontal\n",
    "                transforms.ToTensor(), # Convertir a tensor\n",
    "                transforms.Normalize(imagenet_mean, imagenet_std) # Normalización\n",
    "            ])\n",
    "            # Asignar las transformaciones a la clase correspondiente\n",
    "            class_transforms[real] = aug\n",
    "\n",
    "        elif (real, pred) in [('glacier','sea'), ('sea','glacier')]:\n",
    "            # Augmentations específicas para glaciares y mares\n",
    "            aug = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(input_size, scale=(0.85, 1.0)), # Recorte aleatorio\n",
    "                transforms.RandomRotation(10), # Rotación aleatoria\n",
    "                transforms.ColorJitter(saturation=0.3, brightness=0.2), # Variación de color\n",
    "                transforms.ToTensor(), # Convertir a tensor\n",
    "                transforms.Normalize(imagenet_mean, imagenet_std) # Normalización\n",
    "            ])\n",
    "            # Asignar las transformaciones a la clase correspondiente\n",
    "            class_transforms[real] = aug\n",
    "\n",
    "        else:\n",
    "            # Default augmentation para clases sin confusión frecuente\n",
    "            aug = transforms.Compose([\n",
    "                transforms.Resize((img_size)), # Redimensionar\n",
    "                transforms.RandomHorizontalFlip(p=0.5), # Flip horizontal\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1), # Variación de color\n",
    "                transforms.ToTensor(), # Convertir a tensor\n",
    "                transforms.Normalize(imagenet_mean, imagenet_std) # Normalización\n",
    "            ])\n",
    "            # Asignar las transformaciones a la clase correspondiente\n",
    "            class_transforms[real] = aug\n",
    "\n",
    "    # Devolver las transformaciones por clase\n",
    "    return class_transforms\n",
    "\n",
    "# Obtener las transformaciones personalizadas por clase\n",
    "classwise_transforms = get_classwise_transforms(freq_confusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU3BIu4y54D_"
   },
   "source": [
    "<font color=\"64D7F5\">--Aplicar el Custom Data Augmentation al Dataset--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1756461851396,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "lxJIuQgV6A2s"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Dataset personalizado con transformaciones específicas por clase\n",
    "class CustomDataset(ImageFolder):\n",
    "    # Inicialización del dataset\n",
    "    def __init__(self, root, classwise_transforms, default_transform, apply_prob=0.7, *args, **kwargs):\n",
    "        super().__init__(root, transform=None, *args, **kwargs) # Llamar al constructor de la clase base\n",
    "        self.classwise_transforms = classwise_transforms # Transformaciones específicas por clase\n",
    "        self.default_transform = default_transform # Transformación por defecto\n",
    "        self.apply_prob = apply_prob # Probabilidad de aplicar la transformación\n",
    "\n",
    "    # Obtener un elemento del dataset\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index] # Obtener la ruta y el objetivo\n",
    "        sample = self.loader(path) # Cargar la imagen\n",
    "        class_name = self.classes[target] # Obtener el nombre de la clase\n",
    "        if class_name in self.classwise_transforms and random.random() < self.apply_prob: # Aplicar la transformación con probabilidad\n",
    "          transform = self.classwise_transforms[class_name] # Obtener la transformación correspondiente\n",
    "        else:\n",
    "          transform = self.default_transform # Usar la transformación por defecto\n",
    "\n",
    "        # Aplicar la transformación\n",
    "        if transform is not None:\n",
    "            sample = transform(sample)\n",
    "\n",
    "        # Devolver la muestra y el objetivo\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83w1Rm-Pv4UL"
   },
   "source": [
    "<font color=\"64D7F5\">--Cambiando la entrada del Dataset para que se aplique el Custom Data Augmentation en las clases que se encuentran las confusiones--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2508213,
     "status": "ok",
     "timestamp": 1756464378327,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "EO3OQx5-wHBX",
    "outputId": "adef1f72-4c41-49e7-c882-a009bd121130"
   },
   "outputs": [],
   "source": [
    "# Dataset con augmentations por clase\n",
    "custom_train_ds = CustomDataset(\n",
    "    root=train_dir, # Directorio de entrenamiento\n",
    "    classwise_transforms=classwise_transforms, # Transformaciones específicas por clase\n",
    "    default_transform=train_tfms, # Transformación por defecto\n",
    "    apply_prob=0.7, # Probabilidad de aplicar la transformación\n",
    ")\n",
    "\n",
    "# DataLoader para el conjunto de entrenamiento\n",
    "train_loader_phase2 = DataLoader(custom_train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "# Fase de entrenamiento 2\n",
    "history_phase2 = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "#Reiniciando variables\n",
    "counter = 0 # Reiniciar early stopping\n",
    "best_acc = 0.0 # Nueva variable para alamacenar el best_acc de la Fase 2\n",
    "\n",
    "training_phase2, best_model_wts, best_acc_phase2 = train_model(model, train_loader_phase2, val_loader, criterion, optimizer, device, epochs, best_acc, history_phase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgKvmsS1b9mi"
   },
   "source": [
    "<font color=\"64D7F5\">--Guardado del modelo entrenado en la Fase 2--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "error",
     "timestamp": 1756465099639,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "8bd_Yq5ocO4q",
    "outputId": "862919d7-3c4d-4fc2-e187-34fae1a4416c"
   },
   "outputs": [],
   "source": [
    "# Guardar el modelo de la fase 1\n",
    "save_model(model, type_model, num_classes, save_dir, phase_name=\"phase2\", best_acc=best_acc_phase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fliL7CycSnNU"
   },
   "source": [
    "<font color=\"64D7F5\">--Comparativa entre las dos fases de entrenamiento--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "error",
     "timestamp": 1756465118308,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "95l9vRacSo2l",
    "outputId": "4b222f51-1854-4378-a87b-6aada06f937e"
   },
   "outputs": [],
   "source": [
    "print(\"Comparativa de las dos fases de entrenamiento:\")\n",
    "print(f\"Fase 1: Mejor precisión: {100 * best_acc:.2f}%\")\n",
    "print(f\"Fase 2: Mejor precisión: {100 * best_acc_phase2:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maokL23-0cL6"
   },
   "source": [
    "<font color=\"64D7F5\">--Comparativa grafica entre las dos fases de entrenamiento--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1756465124977,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "3S8YQBcZ0ift",
    "outputId": "dc0b5540-ed8a-40df-e6fa-ff0c288113ef"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Función para graficar la historia de entrenamiento\n",
    "def training_history(history1, history2, label1=\"Fase 1\", label2=\"Fase 2\"):\n",
    "  epochs1 = range(1, len(history1['train_loss']) + 1) # Épocas de la fase 1\n",
    "  epochs2 = range(1, len(history2['train_loss']) + 1) # Épocas de la fase 2\n",
    "\n",
    "  plt.figure(figsize=(12, 5)) # Tamaño de la figura\n",
    "\n",
    "  # Pérdida\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.plot(epochs1, history1['train_loss'], label=f'{label1} Train Loss') # Pérdida de entrenamiento fase 1\n",
    "  plt.plot(epochs1, history1['val_loss'], label=f'{label1} Val Loss') # Pérdida de validación fase 1\n",
    "  plt.plot(epochs2, history2['train_loss'], label=f'{label2} Train Loss') # Pérdida de entrenamiento fase 2\n",
    "  plt.plot(epochs2, history2['val_loss'], label=f'{label2} Val Loss') # Pérdida de validación fase 2\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  plt.title('Evolución de la Pérdida')\n",
    "  plt.grid(True)\n",
    "\n",
    "  # Exactitud\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.plot(epochs1, history1[\"train_acc\"], \"b-\", label=f\"{label1} Train Acc\") # Exactitud de entrenamiento fase 1\n",
    "  plt.plot(epochs1, history1[\"val_acc\"], \"b--\", label=f\"{label1} Val Acc\") # Exactitud de validación fase 1\n",
    "  plt.plot(epochs2, history2[\"train_acc\"], \"g-\", label=f\"{label2} Train Acc\") # Exactitud de entrenamiento fase 2\n",
    "  plt.plot(epochs2, history2[\"val_acc\"], \"g--\", label=f\"{label2} Val Acc\") # Exactitud de validación fase 2\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(\"Accuracy (%)\")\n",
    "  plt.legend()\n",
    "  plt.title(\"Evolución de la Exactitud\")\n",
    "  plt.grid(True)\n",
    "\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "# Graficar la historia de entrenamiento combinada\n",
    "training_history(training_phase1, training_phase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIiX8o0JHZrJ"
   },
   "source": [
    "<font color=\"64D7F5\">--Guardar el historial de entrenamiento--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1883204,
     "status": "aborted",
     "timestamp": 1756461632178,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "SSFXDrJ7He0w"
   },
   "outputs": [],
   "source": [
    "# Guardar el historial\n",
    "import json\n",
    "history_path = os.path.join(save_dir, \"history.json\") # Ruta del historial\n",
    "with open(history_path, \"w\") as f: # Abrir el archivo en modo escritura\n",
    "    json.dump(history, f) # Guardar el historial en formato JSON\n",
    "# Mostrar mensaje de confirmación\n",
    "print(f\"Historial guardado en: {history_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSmmfJzIciwn"
   },
   "source": [
    "<font color=\"64D7F5\">--Cargar el historial de entrenamiento--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1883206,
     "status": "aborted",
     "timestamp": 1756461632181,
     "user": {
      "displayName": "Alex",
      "userId": "01537446484942724560"
     },
     "user_tz": -120
    },
    "id": "keOp7wa_cmWU"
   },
   "outputs": [],
   "source": [
    "# Cargar el historial\n",
    "with open(history_path, \"r\") as f: # Abrir el archivo en modo lectura\n",
    "    history = json.load(f) # Cargar el historial desde el archivo JSON\n",
    "# Mostrar mensaje de confirmación\n",
    "print(\"Historial cargado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
