{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768056bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando modulos\n",
    "import keras_core\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e04e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiendo la ruta del contenido que vamos a usar\n",
    "DATASET_PATH = \"D:\\\\Hacking\\\\Python\\\\AI_Learning\\\\Clasificacion_Imagenes\\\\PetImages\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ed28c",
   "metadata": {},
   "source": [
    "--Filtro para eliminar la imagenes que son sean JPEG--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff00622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "#Definiendo una función para filtrar las imagenes y quedarnos solo\n",
    "#las que sean JPEG\n",
    "def filter_images():\n",
    "    #Iniciamos un contador\n",
    "    deleted_imgs = 0\n",
    "    #Accediendo a los dos directorios donde se encuentran las imagenes\n",
    "    for folder_name in (\"Cat\",\"Dog\"):\n",
    "        #Para acceder a la ruta de cada carpeta\n",
    "        folder_path = os.path.join(DATASET_PATH, folder_name)\n",
    "        #Accediendo a cada imagen de cada directorio\n",
    "        for image in os.listdir(folder_path):\n",
    "            #Para acceder a cada imagen de la carpeta\n",
    "            img_path = os.path.join(folder_path, image)\n",
    "            try:\n",
    "                #Abrimos la imagen \n",
    "                fobj = open(img_path, \"rb\")\n",
    "                #Para comprobar si la imagen esta en formato JPEG\n",
    "                is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "            finally:\n",
    "                #Para cerrar la imagen\n",
    "                fobj.close()\n",
    "            #Si no esta en el formato que queremos(JPEG)\n",
    "            if not is_jfif:\n",
    "                #Augmentamos el contador\n",
    "                deleted_imgs += 1\n",
    "                #Eliminamos la imagen correspondiente\n",
    "                os.remove(img_path)\n",
    "    \n",
    "    #Mostramos por pantalla el numero de imagenes eliminadas\n",
    "    print(f\"Imagenes eliminadas: {deleted_imgs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llamamos a la función para que el filtrado de imagenes se ejecute\n",
    "filter_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42636167",
   "metadata": {},
   "source": [
    "--Conocinedo el tamaño de las imagenes--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "#Definiendo el tamaño de la figura donde se mostraran las imagenes\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "#Para acceder al directorio Dog\n",
    "folder_path = os.path.join(DATASET_PATH, \"Dog\")\n",
    "#Para recorrer las 9 primeras imagenes\n",
    "for i, image in enumerate(os.listdir(folder_path)[:9]):\n",
    "    #Para obtener la ruta completa de la imagen\n",
    "    img_path = os.path.join(folder_path, image)\n",
    "    #Leeemos la imagen\n",
    "    img = mpimg.imread(img_path)\n",
    "    #Organizando la figura\n",
    "    #En este caso tendremos 3 filas y 3 columnas\n",
    "    #subplot(nfilas,ncolumnas,index)\n",
    "    ax = plt.subplot(3,3,i + 1)\n",
    "    #Mostramos la imagen\n",
    "    plt.imshow(img)\n",
    "    #Le ponemos un titulos de la imagen con el tamaño\n",
    "    plt.title(f\"Tamaño: {img.shape[:2][0]} x {img.shape[:2][1]} pixeles\")\n",
    "    #Para que no ponga ejes en la figura\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "#Para mostrar la figura terminada\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3f562",
   "metadata": {},
   "source": [
    "--Definiendo un tamaño común para las imagenes y obteniendo el subconjunto de entrenamiento--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiendo un tamaño de imagen \n",
    "image_size = (180,180)\n",
    "#Tamaño de conjunto de imagenes(Tamaño de lote)\n",
    "batch_size = 128\n",
    "\n",
    "#Para invocar la funcion de obtencion de datos para el entrenamiento\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    validation_split=0.2, #20% de los datos forman parte del subconjunto de validacion\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "#Para obtener el numero de lotes\n",
    "print(f\"Numero de lotes de entrenamiento: {len(train_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0db0e",
   "metadata": {},
   "source": [
    "--Comprovacion del correcto tamaño de las imagenes--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiendo el tamaño de la figura donde se mostraran las imagenes\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "#Para recorrer nuestro conjunto de datos de entrenamiento, concretamente 1 lote(128 ejemplos)\n",
    "for images, labels in train_ds.take(1):\n",
    "    #Para recorrer 9 imagenes\n",
    "    for i in range(9):\n",
    "        #Organizando la figura\n",
    "        #En este caso tendremos 3 filas y 3 columnas\n",
    "        #subplot(nfilas,ncolumnas,index)\n",
    "        ax = plt.subplot(3,3,i + 1)\n",
    "        #Transormando las imagenes a un formato adecuado para que se puedan representar\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        #Le ponemos un titulos de la imagen con el tamaño\n",
    "        plt.title(f\"Tamaño: {images[i].shape[0]} x {images[i].shape[1]} pixeles\")\n",
    "        #Para que no ponga ejes en la figura\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "#Para mostrar la figura terminada\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097d947",
   "metadata": {},
   "source": [
    "--Obtenemos el subconjunto de validacion y pruebas--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0db463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para invocar la funcion de obtencion de datos para el entrenamiento\n",
    "temp_val_ds = keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    validation_split=0.2, #20% de los datos forman parte del subconjunto de validacion\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "#Para mostrar el numero de lotes de validacion\n",
    "print(f\"Numero de lotes de validación: {len(temp_val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cac3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#De este conjunto de lotes nos quedaremos con la mitad para validacion\n",
    "#y la otra mitad para pruebas\n",
    "val_size = int(0.5 * len(temp_val_ds))\n",
    "val_ds = temp_val_ds.take(val_size)\n",
    "test_ds = temp_val_ds.skip(val_size)\n",
    "print(f\"La cantidad de lotes para la validación són: {len(val_ds)}\")\n",
    "print(f\"La cantidad de lotes para las pruebas són: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b024af",
   "metadata": {},
   "source": [
    "--Otra forma de obtenencion del subconjunto de validacion y pruebas--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b397d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split no puede trabajar con objetos Dataset de Tensorflow\n",
    "# Esto supone un incremento del consumo de memoria RAM\n",
    "#Por eso lo convertiremos en una lista\n",
    "val_ds_sk = list(temp_val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08961b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para crear el modelo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Para dividir del conjunto de validación en validación y pruebas\n",
    "val_ds_sk, test_ds_sk = train_test_split(\n",
    "    val_ds_sk,\n",
    "    test_size=0.5,  #Porcentaje para prueba\n",
    "    random_state=42,    #Semilla para reproducibilidad\n",
    ")\n",
    "print(f\"La cantidad de lotes para la validación són: {len(val_ds_sk)}\")\n",
    "print(f\"La cantidad de lotes para las pruebas són: {len(test_ds_sk)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bfd7d3",
   "metadata": {},
   "source": [
    "--Definiendo La arquitectura de nuestra red neurona--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "#Definiendo la dimension de los datos de entrada (pixles x pixeles, rgb)\n",
    "input_shape = (180,180,3)\n",
    "\n",
    "#Definiendo la red neuronal, en este caso sera sequencial\n",
    "fcnn_model = keras.Sequential()\n",
    "\n",
    "#Definiendo las diferentes capas\n",
    "#Entrada de la red neuronal\n",
    "fcnn_model.add(layers.Input(shape=input_shape))\n",
    "\n",
    "#Escalando las imagenes\n",
    "fcnn_model.add(layers.Rescaling(1.0 / 255))\n",
    "\n",
    "#Estirar o aplanar las imagenes para la primera capa densa\n",
    "fcnn_model.add(layers.Flatten())\n",
    "\n",
    "#Capa 1 (Numero de neuronas, función matemàtica)\n",
    "fcnn_model.add(layers.Dense(384, activation='relu'))\n",
    "\n",
    "#Capa 2 (Numero de neuronas, función matemàtica)\n",
    "fcnn_model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "#Capa 3 (Numero de neuronas, función matemàtica)\n",
    "fcnn_model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "#Capa 4 - Output Layer. Terminamos con una neurona\n",
    "#ya que lo que queremos es una clasificación binaria de los datos(gato o perro)\n",
    "#(Numero de neuronas, función matemàtica)\n",
    "#Si fuesen dos o mas neuronas/clases deberiamos cambiar\n",
    "#la función de activación por 'softmax'\n",
    "fcnn_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37514f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ver un resumen de lo que hemos hecho previamente\n",
    "fcnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ver las diferentes capas\n",
    "fcnn_model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a6e4f",
   "metadata": {},
   "source": [
    "--Configurando nuestra red neuronal--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c066c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilamos el primer modelo de FCNN\n",
    "#loss --> Classificacion de Error binaria. Si no fuese binaria habria que poner 'categorical_crossentropy'\n",
    "#optimizer --> Adam de las más utilizadas. Adam(Learning Rate)\n",
    "#metrics --> Función utilizada para la red neuronal\n",
    "fcnn_model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b7a78",
   "metadata": {},
   "source": [
    "--Entrenando nuestra red neuronal--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acf228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceso de entrenamiento\n",
    "#epochs --> Las vueltas que da sobre los datos de entrenamiento\n",
    "history = fcnn_model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02ed9b",
   "metadata": {},
   "source": [
    "--Grafica para ver la tendencia de los valores de error y exactitud--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Transformar la variable de history(donde estan almacenados los datos)\n",
    "#en un DataFrame para mostrarlos por pantalla\n",
    "pd.DataFrame(history.history).plot(figsize=(10, 7))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1.2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()\n",
    "\n",
    "#Si el entrenamiento es adecuado deberiamos ver\n",
    "#como la linea de fallo tiende a disminuir y\n",
    "#la linia de exactitud tiende a incrementar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd27ed",
   "metadata": {},
   "source": [
    "--Para guardar/almacenar el modelo entrenado en el disco y así no perder el tiempo entrenado--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879905cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el módulo de guardado\n",
    "from keras.saving import load_model\n",
    "\n",
    "#Guardamos el modelo en disco\n",
    "fcnn_model.save(\"D:\\\\Hacking\\\\Python\\\\AI_Learning\\\\Clasificacion_Imagenes.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b8c53",
   "metadata": {},
   "source": [
    "--Para volver a cargar el modelo ya entrenado--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980598d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el módulo de guardado\n",
    "from keras.saving import load_model\n",
    "\n",
    "#Para cargar el modelo ya entrenado\n",
    "fcnn_model_disk = keras.models.load_model(\"D:\\\\Hacking\\\\Python\\\\AI_Learning\\\\Clasificacion_Imagenes.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05ce8d",
   "metadata": {},
   "source": [
    "--Predicción de nuevos ejemplos: Para saber como se comporta el modelo frente a nuevos ejemplos--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para evaluar el modelo con el conjunto de datos de pruebas\n",
    "evaluation_result = fcnn_model_disk.evaluate(test_ds)\n",
    "\n",
    "#Para mostrar las metrica de evaluación de los ejemplos(precisión y perdida) \n",
    "print(\"Loss:\", evaluation_result[0])\n",
    "print(\"Accuracy:\", evaluation_result[1])\n",
    "\n",
    "#Los resultados tendrian que oscilar entre los resultados finales del entrenamiento\n",
    "#para saber que ha habido un correcto funcionamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a38c0",
   "metadata": {},
   "source": [
    "--Demostración de como actua nuesto modelo entrenado--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71705963",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for images, labels in test_ds.take(1): #take(1) obtiene un lote del conjunto de datos (128 ejemplos)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3,3,i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        predictions = fcnn_model_disk.predict(tf.expand_dims(images[i], 0))\n",
    "        score = float(predictions[0])    \n",
    "        plt.title(f\"Cat: {100 * (1 - score):.2f}%, Dog: {100 * score:.2f}%\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf715b",
   "metadata": {},
   "source": [
    "--Mejorando los resultados obtenidos--\n",
    "IMPORTANTE: REINICIAR EL ENTORNO\n",
    "Se necesita reiniciar el entorno ya que se encuentra muy cargado y al hacer mejoras importante en los resultados necesitaremos rendimiento del que ya hemos usado previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aecfdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos de vuelta los modulos que usaremos\n",
    "from tensorflow import keras\n",
    "\n",
    "#Introduciomos variables importantes\n",
    "DATASET_PATH = \"D:\\\\Hacking\\\\Python\\\\AI_Learning\\\\Clasificacion_Imagenes\\\\PetImages\"\n",
    "\n",
    "#Lectura de nuestro Train Dataset\n",
    "image_size = (180,180)\n",
    "batch_size = 128\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#Obtención de nuestro Validation Dataset\n",
    "temp_val_ds = keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#Obtención de nuestro Test Dataset\n",
    "val_size = int(0.5 * len(temp_val_ds))\n",
    "val_ds = temp_val_ds.take(val_size)\n",
    "test_ds = temp_val_ds.skip(val_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022b456",
   "metadata": {},
   "source": [
    "--Augmentando el conjunto de datos--\n",
    "Este principio usa las imagenes ya utilizadas por el modelo modificandolas(ya sea cambiando su orientación o rotación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef99705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando modulo necesario\n",
    "from keras import layers\n",
    "\n",
    "#Para transformar las imagenes(horizontal y con una rotación)\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db134490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recorriendo las imagenes del primer batch de entrenamiento transformada\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3,3,i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#Aplicamos nuestro \"data augmentation\" al conjunto de datos de entrenamiento\n",
    "train_ds = train_ds.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b46e1e8",
   "metadata": {},
   "source": [
    "--Mejorando la Red Neuronal Artificial--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a49ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiendo el nuevo modelo RNA(API Funcional)\n",
    "def make_model(input_shape, num_classes):\n",
    "    \n",
    "    #Entrada de nuestros datos\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    #El output de la primera capa se junta con el imput de la segunda capa\n",
    "    #Capa de escalado de imagenes\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    #Capa convolucional\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    #Capa de normalización\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #Capa de activacion\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    #Guardando la variable con las capas seteadas\n",
    "    previous_block_activation = x\n",
    "    \n",
    "    #Usando un bucle para definir las siguentes capas con diferentes tamaños de neuronas\n",
    "    for size in [256, 512, 728]:\n",
    "        #Capa de activación \n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        #Capa convolucional\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        #Capa de normalización\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        #Capa de activacion\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        #Capa convolucional\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        #Capa de normalización\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        #Capa de agrupación\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "        \n",
    "        #Conexion residual\n",
    "        residual = layers.Conv2D(size, 1 ,strides=2, padding=\"same\")(previous_block_activation)        \n",
    "        x = layers.add([x, residual]) #Agregando residuo\n",
    "        previous_block_activation = x #Reservando el siguiente residuo\n",
    "    \n",
    "    #Capa convolucional  \n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    #Capa de normalización\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #Capa de activacion\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    #Condicional para la configuración del modelo\n",
    "    #activation --> la funcion de activación que debe usar\n",
    "    #units --> Output layer, el numero de neuronas de la ultima cap \n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "    \n",
    "    #Capa de regularización\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    #Output layers o ultima capa\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para construir el modelo\n",
    "#num_classes --> clasificacion binaria en este caso\n",
    "xception = make_model(input_shape=(180,180,3), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cfdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrando resumen\n",
    "xception.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad3400b",
   "metadata": {},
   "source": [
    "--Configuración y entrenamiento de la Red Neuronal Artificial--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc924431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilamos el modelo\n",
    "xception.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable de entrenamiento del modelo\n",
    "history = xception.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba1f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(10, 7))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1.2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
